{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a420ccf-da46-4547-8fac-32e27cbb7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mtidyr\u001b[39m::\u001b[32mextract()\u001b[39m      masks \u001b[34mmagrittr\u001b[39m::extract()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m       masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m          masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mmagrittr\u001b[39m::\u001b[32mset_names()\u001b[39m masks \u001b[34mpurrr\u001b[39m::set_names()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(purrr)\n",
    "library(httr)\n",
    "library(tidyverse)\n",
    "library(magrittr) # <-- THIS gives you %>%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd79048-338a-47b7-9772-27388dde4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text <- function(text) {\n",
    "  text %>%\n",
    "    tolower() %>%\n",
    "    str_extract_all(\"\\\\w+|[[:punct:]]\") %>%\n",
    "    unlist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2336ef16-2660-4a48-91ef-3b91102d1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_keys <- function(tokens, n) {\n",
    "  keys <- map_chr(\n",
    "    1:(length(tokens) - n + 1),\n",
    "    ~ paste(tokens[.x:(.x + n - 2)], collapse = \" \")\n",
    "  )\n",
    "  return(keys)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c3026b-61ae-4f67-a74e-2a7953abaf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n = 3) {\n",
    "  \n",
    "  keys <- generate_keys(tokens, n)\n",
    "  \n",
    "  next_words <- tokens[n:length(tokens)]\n",
    "  \n",
    "  tibble(\n",
    "    key = keys,\n",
    "    next_word = next_words\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c434a0-82a0-4f0f-a12d-63a0d37a29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n = 3) {\n",
    "  tokens <- tokenize_text(text)\n",
    "  build_ngram_table(tokens, n)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a277964-e261-48b2-b15d-f7f506c7657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n = 3) {\n",
    "  response <- httr::GET(url)\n",
    "  text <- content(response, as = \"text\")\n",
    "  digest_text(text, n)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac3f1a8-d2de-4e39-9848-df6106ab3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(model) {\n",
    "  sample(unique(model$key), 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d51378a-c641-485f-bc20-f2caca868e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(model, key) {\n",
    "  choices <- model %>% filter(key == !!key) %>% pull(next_word)\n",
    "  \n",
    "  if (length(choices) == 0) {\n",
    "    return(NULL)\n",
    "  }\n",
    "  \n",
    "  sample(choices, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff7050f-15db-49ed-b81c-958f4dc82b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text <- function(model, start_words = NULL, n = 3, length = 40) {\n",
    "  \n",
    "  # choose start key\n",
    "  if (is.null(start_words)) {\n",
    "    key <- random_start(model)\n",
    "  } else {\n",
    "    key <- tolower(start_words)\n",
    "    \n",
    "    # make sure key is valid\n",
    "    if (!(key %in% model$key)) {\n",
    "      stop(\"Start words not found in model.\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  output <- unlist(str_split(key, \" \"))\n",
    "  \n",
    "  for (i in 1:length) {\n",
    "    next_word <- predict_next_word(model, key)\n",
    "    \n",
    "    # no continuation → stop early\n",
    "    if (is.null(next_word)) break\n",
    "    \n",
    "    output <- c(output, next_word)\n",
    "    \n",
    "    # advance the key by one word\n",
    "    last_words <- tail(output, n - 1)\n",
    "    key <- paste(last_words, collapse = \" \")\n",
    "  }\n",
    "  \n",
    "  paste(output, collapse = \" \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9ae2059-b7da-44ba-a77b-acc7f9f1ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "text <- \"This is a simple example text. This is only an example to demonstrate an ngram model.\"\n",
    "\n",
    "model <- digest_text(text, n = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10f9119a-0b95-474b-992b-2b04a652c139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'this is a simple example text . this is a simple example text . this is a simple example text . this is only an example to demonstrate an ngram model .'"
      ],
      "text/latex": [
       "'this is a simple example text . this is a simple example text . this is a simple example text . this is only an example to demonstrate an ngram model .'"
      ],
      "text/markdown": [
       "'this is a simple example text . this is a simple example text . this is a simple example text . this is only an example to demonstrate an ngram model .'"
      ],
      "text/plain": [
       "[1] \"this is a simple example text . this is a simple example text . this is a simple example text . this is only an example to demonstrate an ngram model .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(model, start_words = \"this is\", n = 3, length = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a427548-36fb-45a2-8a26-dabdf538883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'is only an example to demonstrate an ngram model .'"
      ],
      "text/latex": [
       "'is only an example to demonstrate an ngram model .'"
      ],
      "text/markdown": [
       "'is only an example to demonstrate an ngram model .'"
      ],
      "text/plain": [
       "[1] \"is only an example to demonstrate an ngram model .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(model, n = 3, length = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523821c3-b30e-4654-8877-c35d2fbb5c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'the king of a thousand times better off , and went away . ’ so the fisherman'"
      ],
      "text/latex": [
       "'the king of a thousand times better off , and went away . ’ so the fisherman'"
      ],
      "text/markdown": [
       "'the king of a thousand times better off , and went away . ’ so the fisherman'"
      ],
      "text/plain": [
       "[1] \"the king of a thousand times better off , and went away . ’ so the fisherman\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'he now flew to the king had come and devour her in it , and away they'"
      ],
      "text/latex": [
       "'he now flew to the king had come and devour her in it , and away they'"
      ],
      "text/markdown": [
       "'he now flew to the king had come and devour her in it , and away they'"
      ],
      "text/plain": [
       "[1] \"he now flew to the king had come and devour her in it , and away they\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "grimm_text  <- readr::read_file(\"Grimm.txt\")\n",
    "model_grimm  <- digest_text(grimm_text, n = 3)\n",
    "generate_text(model_grimm, start_words = \"the king\", n = 3, length = 15)\n",
    "generate_text(model_grimm, start_words =NULL, n = 3, length = 15)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed237bd6-fc05-49d8-b2cf-cb896e912d61",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5afba8e6-1bc9-4bc0-b4c9-89ada2b06b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'the king and with what weapons they contended , thematerial of their ships . matthew paris ,'"
      ],
      "text/latex": [
       "'the king and with what weapons they contended , thematerial of their ships . matthew paris ,'"
      ],
      "text/markdown": [
       "'the king and with what weapons they contended , thematerial of their ships . matthew paris ,'"
      ],
      "text/plain": [
       "[1] \"the king and with what weapons they contended , thematerial of their ships . matthew paris ,\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'written towards the close of the realm , \" &amp; c . 59 . 317 84 .'"
      ],
      "text/latex": [
       "'written towards the close of the realm , \" \\& c . 59 . 317 84 .'"
      ],
      "text/markdown": [
       "'written towards the close of the realm , \" &amp; c . 59 . 317 84 .'"
      ],
      "text/plain": [
       "[1] \"written towards the close of the realm , \\\" & c . 59 . 317 84 .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "Antient_text  <- readr::read_file(\"Antient.txt\")\n",
    "model_Antient  <- digest_text(Antient_text, n = 3)\n",
    "generate_text(model_Antient, start_words = \"the king\", n = 3, length = 15)\n",
    "generate_text(model_Antient, start_words =NULL, n = 3, length = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0160464-1105-49cd-a0ee-93836a7ae8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "One code looks for text \"the king\" to generate the text based on the text found, while the other code randomly generates text, becayse the start text is not assigned in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccab975-1717-40d6-899b-9692127ad5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a) A language learning model is a artificial intelligence system that is trained on large text data to recognize patterns in the text and predict and generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540a67f-a2dc-4316-9b40-28a4bcdf8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "b) To run a language model locally on your computer, you need a softare like OLLAMAm that can be installed through Homebrew. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | It is the program that interpretts the commands mkdir project |\n",
    "| **Terminal emulator** | It is the app window where you would enter mkdir project  |\n",
    "| **Process** | It is a running instance of a program |\n",
    "| **Signal** | It is a message sent  |\n",
    "| **Standard input** | A stream from which a program reads input |\n",
    "| **Standard output** | A stream where program write output |\n",
    "| **Command line argument** | Extra text added after a command that modifies what it does |\n",
    "| **The environment** | A set of key variables that influence how program run |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f30ec9-cebd-4e5f-b196-2b8cf609e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a)find , Xargs and grep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490838da-77bf-433a-9b66-ddfb5239bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "b)This command will find in the corrent directory all files ending in \".R\" (basically all r files), then xargs takes all the R files from the previous command, and grep  searchers for text \"read_csv\" inside each R file. It results in prints all of all lines where someone uses \"read _csv\" in any of the R files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33180a06-575d-4215-9e27-207f63a69fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a) Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (arm64v8)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494d132-dbc3-47c7-9a0e-763e38246aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b) docker run -d \\\n",
    "  --name rstudio \\\n",
    "  -p 8787:8787 \\\n",
    "  -e PASSWORD= \\\n",
    "  -v \"$PWD\":/home/rstudio \\\n",
    "  rocker/rstudio\n",
    "\n",
    "output \n",
    "Unable to find image 'rocker/rstudio:latest' locally\n",
    "latest: Pulling from rocker/rstudio\n",
    "d960726af2be: Pull complete\n",
    "bb7d5a84853b: Pull complete\n",
    "c7fb3351ecad: Pull complete\n",
    "c780c6d5a2e3: Pull complete\n",
    "f1e1a2ac89da: Pull complete\n",
    "34d3f43291e2: Pull complete\n",
    "Digest: sha256:af3c38c946d94c44b1df38e4b3db0b791bcb4d112067998bb4a730d5cb9bf7e7\n",
    "Status: Downloaded newer image for rocker/rstudio:latest\n",
    "8b4ae90c72df8f1fe37c97974b8a0bc54f6aef7289fa9e61274c2f7ddc6a12ce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a6f06-46f3-49a5-b834-fd2f32204fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "c)To log into the Rstudio server, i enter the link \"http://localhost:8787/\" into the browser and using the login username rstudio and the possword that i set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
