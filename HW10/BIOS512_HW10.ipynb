{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a420ccf-da46-4547-8fac-32e27cbb7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘magrittr’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    set_names\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(purrr)\n",
    "library(httr)\n",
    "library(magrittr)   # <-- THIS gives you %>%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fd79048-338a-47b7-9772-27388dde4e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text <- function(text) {\n",
    "  text %>%\n",
    "    tolower() %>%\n",
    "    str_extract_all(\"\\\\w+|[[:punct:]]\") %>%\n",
    "    unlist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2336ef16-2660-4a48-91ef-3b91102d1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_keys <- function(tokens, n) {\n",
    "  keys <- map_chr(\n",
    "    1:(length(tokens) - n + 1),\n",
    "    ~ paste(tokens[.x:(.x + n - 2)], collapse = \" \")\n",
    "  )\n",
    "  return(keys)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c3026b-61ae-4f67-a74e-2a7953abaf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n = 3) {\n",
    "  \n",
    "  keys <- generate_keys(tokens, n)\n",
    "  \n",
    "  next_words <- tokens[n:length(tokens)]\n",
    "  \n",
    "  tibble(\n",
    "    key = keys,\n",
    "    next_word = next_words\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c434a0-82a0-4f0f-a12d-63a0d37a29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n = 3) {\n",
    "  tokens <- tokenize_text(text)\n",
    "  build_ngram_table(tokens, n)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a277964-e261-48b2-b15d-f7f506c7657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n = 3) {\n",
    "  response <- httr::GET(url)\n",
    "  text <- content(response, as = \"text\")\n",
    "  digest_text(text, n)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac3f1a8-d2de-4e39-9848-df6106ab3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(model) {\n",
    "  sample(unique(model$key), 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d51378a-c641-485f-bc20-f2caca868e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(model, key) {\n",
    "  choices <- model %>% filter(key == !!key) %>% pull(next_word)\n",
    "  \n",
    "  if (length(choices) == 0) {\n",
    "    return(NULL)\n",
    "  }\n",
    "  \n",
    "  sample(choices, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff7050f-15db-49ed-b81c-958f4dc82b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text <- function(model, start_words = NULL, n = 3, length = 40) {\n",
    "  \n",
    "  # choose start key\n",
    "  if (is.null(start_words)) {\n",
    "    key <- random_start(model)\n",
    "  } else {\n",
    "    key <- tolower(start_words)\n",
    "    \n",
    "    # make sure key is valid\n",
    "    if (!(key %in% model$key)) {\n",
    "      stop(\"Start words not found in model.\")\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  output <- unlist(str_split(key, \" \"))\n",
    "  \n",
    "  for (i in 1:length) {\n",
    "    next_word <- predict_next_word(model, key)\n",
    "    \n",
    "    # no continuation → stop early\n",
    "    if (is.null(next_word)) break\n",
    "    \n",
    "    output <- c(output, next_word)\n",
    "    \n",
    "    # advance the key by one word\n",
    "    last_words <- tail(output, n - 1)\n",
    "    key <- paste(last_words, collapse = \" \")\n",
    "  }\n",
    "  \n",
    "  paste(output, collapse = \" \")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ae2059-b7da-44ba-a77b-acc7f9f1ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "text <- \"This is a simple example text. This is only an example to demonstrate an ngram model.\"\n",
    "\n",
    "model <- digest_text(text, n = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f9119a-0b95-474b-992b-2b04a652c139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'this is only an example to demonstrate an ngram model .'"
      ],
      "text/latex": [
       "'this is only an example to demonstrate an ngram model .'"
      ],
      "text/markdown": [
       "'this is only an example to demonstrate an ngram model .'"
      ],
      "text/plain": [
       "[1] \"this is only an example to demonstrate an ngram model .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(model, start_words = \"this is\", n = 3, length = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a427548-36fb-45a2-8a26-dabdf538883b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'only an example to demonstrate an ngram model .'"
      ],
      "text/latex": [
       "'only an example to demonstrate an ngram model .'"
      ],
      "text/markdown": [
       "'only an example to demonstrate an ngram model .'"
      ],
      "text/plain": [
       "[1] \"only an example to demonstrate an ngram model .\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_text(model, n = 3, length = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "523821c3-b30e-4654-8877-c35d2fbb5c77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'www.gutenberg.org' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'www.gutenberg.org' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "urlgrimm <- www.gutenberg.org/cache/epub/2591/pg2591.txt\n",
    "grimm_text <- read_lines(urlgrimm)\n",
    "model_grimm <- digest_text(grimm_text, n=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed237bd6-fc05-49d8-b2cf-cb896e912d61",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** |  |\n",
    "| **Terminal emulator** |  |\n",
    "| **Process** |  |\n",
    "| **Signal** |  |\n",
    "| **Standard input** |  |\n",
    "| **Standard output** |  |\n",
    "| **Command line argument** |  |\n",
    "| **The environment** |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
